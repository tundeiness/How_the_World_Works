# How the world works Cornerstone Project
## Exercise One: Fake it Til You Make it
- Import required libraries like Numpy, Pandas, Matplotlib, Seaborn and pyplot
- Explored the libraries
-Generating placeholder data using np.linspace
- Creating random samples with Numpy and creating sample for sine wave and Tan wave(sine and tan wave       simulation)
- Simulating Noise to make data realistic
- Importing data using pandas read_csv
- Exploring Normal Distribution and standard deviation values as it affects normal distribution shapes
- Implement Sport Betting exercise. 

## Exercise Two: Building Simple Mean Models and Linear Regression Models
- Mean Model
- visually evaluate how the mean model "fits" the training data using graphs
  1. overlay the mean model predictions with the original dataset using plt.plot() for line plot and plt.scatter() to plot the training data. 
- evaluate mean model visually
- implement linear regression model using scikit learn module
- evaluate linear regression model vs training data

### Introduction to Model Parameters 

                     Model     |     Model Parameter

     Mean Model                |   average value of y
     Linear Regression Model   |   intercept and coefficient


- how model parameter defines individual models
- make prediction manually using intercept and co-efficient
- assign new values to intercept and co-efficient
 

## Polynomial Regression and Model Parameters

- implement second order polynomial Linear Regression
- implement Helper Functions
- implement x order polynomial Linear Regression
- implement model with 2 non-sequential polynomial terms.

### Model complexity
- In the context of Linear and Polynomial regression, this refers to :
   (1) Number of model parameters ( i.e  𝛽1 𝛽2 or 𝛽3 )
   (2) effectiveness in expressing relationship within the dataset(Model parameter effectiveness)
- where there is a model with 2 non-sequential polynomial terms: Like fitting and plotting a model with  𝑥,𝑥3,and 𝑥5 as input features. These are non sequential as observed.

## Exercise 3.1: 

## Exercise 3.2:

## Exercise 3.3: 

